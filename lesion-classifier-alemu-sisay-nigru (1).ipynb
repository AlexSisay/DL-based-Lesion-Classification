{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\nAuthor: Alemu Sisay Nigru\nMatricola Number: 730159\n'''","metadata":{"id":"0DHCXPfVgInz","outputId":"e59c0df7-87b9-43ae-c480-f55f260622d5","execution":{"iopub.status.busy":"2022-01-03T06:41:57.100929Z","iopub.execute_input":"2022-01-03T06:41:57.101858Z","iopub.status.idle":"2022-01-03T06:42:07.341772Z","shell.execute_reply.started":"2022-01-03T06:41:57.101746Z","shell.execute_reply":"2022-01-03T06:42:07.340949Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#!pip install keras-tuner\n!pip install torchsummary","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom torchsummary import summary\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import models,transforms\n#base_skin_dir = os.path.join('..', 'input')\n","metadata":{"id":"dUIN0TbjEIvw","execution":{"iopub.status.busy":"2022-01-03T06:42:07.343560Z","iopub.execute_input":"2022-01-03T06:42:07.343823Z","iopub.status.idle":"2022-01-03T06:42:10.132643Z","shell.execute_reply.started":"2022-01-03T06:42:07.343781Z","shell.execute_reply":"2022-01-03T06:42:10.131860Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#from keras_tuner import RandomSearch\n#from keras_tuner.engine.hyperparameters import HyperParameters\nimport torch\nfrom torch import optim,nn\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import models,transforms\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"id":"6iEAmAyOOsLf","outputId":"b98c2eee-cd81-4028-fc5d-210ccb5202b6","execution":{"iopub.status.busy":"2022-01-03T06:42:10.135298Z","iopub.execute_input":"2022-01-03T06:42:10.135812Z","iopub.status.idle":"2022-01-03T06:42:14.000320Z","shell.execute_reply.started":"2022-01-03T06:42:10.135770Z","shell.execute_reply":"2022-01-03T06:42:13.999541Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\npaths = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\ndf_all = pd.read_csv('../input/ground-truth/HAM10000_metadata (1).csv')\ndf_all.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T06:42:14.002452Z","iopub.execute_input":"2022-01-03T06:42:14.002732Z","iopub.status.idle":"2022-01-03T06:42:29.246785Z","shell.execute_reply.started":"2022-01-03T06:42:14.002696Z","shell.execute_reply":"2022-01-03T06:42:29.246113Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount(\"/content/drive\", force_remount=True)\nground_truth = '../input/ground-truth/HAM10000_metadata (1).csv'\nbase_skin_dir = \"../input/skin-cancer-mnist-ham10000\"","metadata":{"id":"yRhEzghcEuZy","outputId":"3573ac63-db97-419c-96db-226a4a7b330c","execution":{"iopub.status.busy":"2022-01-03T06:42:29.247880Z","iopub.execute_input":"2022-01-03T06:42:29.248129Z","iopub.status.idle":"2022-01-03T06:42:29.255124Z","shell.execute_reply.started":"2022-01-03T06:42:29.248092Z","shell.execute_reply":"2022-01-03T06:42:29.252802Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\nprint(len(imageid_path_dict))\nlesion_type_dict = {\n    'nv': 'Melanocytic nevus',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}","metadata":{"id":"N4iN0tDbEZoQ","execution":{"iopub.status.busy":"2022-01-03T06:42:29.257031Z","iopub.execute_input":"2022-01-03T06:42:29.257723Z","iopub.status.idle":"2022-01-03T06:42:29.396764Z","shell.execute_reply.started":"2022-01-03T06:42:29.257686Z","shell.execute_reply":"2022-01-03T06:42:29.396055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_all = pd.read_csv(ground_truth)\ndf_all['path'] = df_all['image_id'].map(imageid_path_dict.get)\ndf_all['cell_type'] = df_all['dx'].map(lesion_type_dict.get) \ndf_all['cell_type_idx'] = pd.Categorical(df_all['cell_type']).codes\ndf_all.head()","metadata":{"id":"3s1IkLNrEqH_","outputId":"8bbf21e6-1520-467a-cf60-8824a708aeab","execution":{"iopub.status.busy":"2022-01-03T06:42:29.397970Z","iopub.execute_input":"2022-01-03T06:42:29.398375Z","iopub.status.idle":"2022-01-03T06:42:29.445156Z","shell.execute_reply.started":"2022-01-03T06:42:29.398340Z","shell.execute_reply":"2022-01-03T06:42:29.444448Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_all.describe(exclude=[np.number])","metadata":{"id":"2ZAijSSaIIx6","outputId":"0875aa9b-b274-43cf-c098-127363577f69","execution":{"iopub.status.busy":"2022-01-03T06:42:29.446349Z","iopub.execute_input":"2022-01-03T06:42:29.446595Z","iopub.status.idle":"2022-01-03T06:42:29.501379Z","shell.execute_reply.started":"2022-01-03T06:42:29.446564Z","shell.execute_reply":"2022-01-03T06:42:29.500590Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_df = df_all[df_all['dx']=='df']\ndf_vasc = df_all[df_all['dx']=='vasc']\ndf_akiec = df_all[df_all['dx']=='akiec']\ndf_bcc = df_all[df_all['dx']=='bcc']\ndf_bkl = df_all[df_all['dx']=='bkl']\ndf_mel = df_all[df_all['dx']=='mel']\ndf_nv = df_all[df_all['dx']=='nv'][:1690]\ndf_all = pd.concat([df_df,df_vasc,df_akiec,df_bcc,df_bkl,df_mel,df_nv],ignore_index=True)\nlen(df_all)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T06:42:29.502748Z","iopub.execute_input":"2022-01-03T06:42:29.502995Z","iopub.status.idle":"2022-01-03T06:42:29.534736Z","shell.execute_reply.started":"2022-01-03T06:42:29.502962Z","shell.execute_reply":"2022-01-03T06:42:29.534052Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_all['dx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T06:42:29.537600Z","iopub.execute_input":"2022-01-03T06:42:29.537784Z","iopub.status.idle":"2022-01-03T06:42:29.544323Z","shell.execute_reply.started":"2022-01-03T06:42:29.537761Z","shell.execute_reply":"2022-01-03T06:42:29.543429Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (10, 5))\ndf_all['dx'].value_counts().plot(kind='bar', ax=ax1)\ndf_all['cell_type'].value_counts()","metadata":{"id":"Jr872iFNNZUG","outputId":"cf6af8c5-a40c-4c22-bef9-dd9adb479d7f","execution":{"iopub.status.busy":"2022-01-03T06:42:29.545542Z","iopub.execute_input":"2022-01-03T06:42:29.545979Z","iopub.status.idle":"2022-01-03T06:42:29.783619Z","shell.execute_reply.started":"2022-01-03T06:42:29.545943Z","shell.execute_reply":"2022-01-03T06:42:29.782966Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def compute_img_mean_std(image_paths):\n    \"\"\"\n        computing the mean and std of three channel on the whole dataset,\n        first we should normalize the image from 0-255 to 0-1\n    \"\"\"\n\n    img_h, img_w = 128, 128\n    imgs = []\n    means, stdevs = [], []\n\n    for i in tqdm(range(len(image_paths))):\n        img = cv2.imread(image_paths[i])\n        img = cv2.resize(img, (img_h, img_w))\n        imgs.append(img)\n\n    imgs = np.stack(imgs, axis=3)\n    print(imgs.shape)\n\n    imgs = imgs.astype(np.float32) / 255.\n\n    for i in range(3):\n        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n        means.append(np.mean(pixels))\n        stdevs.append(np.std(pixels))\n\n    means.reverse()  # BGR --> RGB\n    stdevs.reverse()\n\n    print(\"normMean = {}\".format(means))\n    print(\"normStd = {}\".format(stdevs))\n    return means,stdevs","metadata":{"id":"iQLIi66Gsipp","execution":{"iopub.status.busy":"2022-01-03T06:42:29.784870Z","iopub.execute_input":"2022-01-03T06:42:29.785136Z","iopub.status.idle":"2022-01-03T06:42:29.793396Z","shell.execute_reply.started":"2022-01-03T06:42:29.785104Z","shell.execute_reply":"2022-01-03T06:42:29.792068Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"all_image_path = df_all['path']\nnorm_mean,norm_std = compute_img_mean_std(all_image_path)","metadata":{"id":"rk_1hQjDsisy","outputId":"8ee869ae-ce30-4dc3-e9ba-09350b34c9bb","execution":{"iopub.status.busy":"2022-01-03T06:42:29.794924Z","iopub.execute_input":"2022-01-03T06:42:29.795232Z","iopub.status.idle":"2022-01-03T06:43:52.576816Z","shell.execute_reply.started":"2022-01-03T06:42:29.795197Z","shell.execute_reply":"2022-01-03T06:43:52.576014Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# now we create a val set using df because we are sure that none of these images have augmented duplicates in the train set\ny = df_all['cell_type_idx']\n_, df_temp = train_test_split(df_all, test_size=0.3, random_state=101, stratify=y)\nlabel = df_temp['cell_type_idx']\ndf_val, df_test= train_test_split(df_temp, test_size=0.5, random_state=25, stratify=label)\ndf_test.shape","metadata":{"id":"dMzhCLORvCHv","outputId":"e8b744a0-fca2-416a-8a84-5b700a21575c","execution":{"iopub.status.busy":"2022-01-03T06:43:52.578025Z","iopub.execute_input":"2022-01-03T06:43:52.578291Z","iopub.status.idle":"2022-01-03T06:43:52.599797Z","shell.execute_reply.started":"2022-01-03T06:43:52.578252Z","shell.execute_reply":"2022-01-03T06:43:52.599066Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_val['cell_type_idx'].value_counts()","metadata":{"id":"r28DAinHvCK4","outputId":"d1069ba4-2f78-456e-e0a2-7edb085f98a1","execution":{"iopub.status.busy":"2022-01-03T06:43:52.600878Z","iopub.execute_input":"2022-01-03T06:43:52.601144Z","iopub.status.idle":"2022-01-03T06:43:52.609604Z","shell.execute_reply.started":"2022-01-03T06:43:52.601109Z","shell.execute_reply":"2022-01-03T06:43:52.608786Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# This set will be df_original excluding all rows that are in the val set\n# This function identifies if an image is part of the train or val set.\ndef get_val_rows(x):\n    # create a list of all the lesion_id's in the val set\n    val_list = list(df_val['image_id'])\n    test_list = list(df_test['image_id'])\n    if str(x) in val_list:\n        return 'val'\n    elif str(x) in test_list:\n        return 'test'\n    else:\n        return 'train'\n\n# identify train and val rows\n# create a new colum that is a copy of the image_id column\ndf_all['train_val_or_test'] = df_all['image_id']\n# apply the function to this new column\ndf_all['train_val_or_test'] = df_all['train_val_or_test'].apply(get_val_rows)\n# filter out train rows\ndf_train = df_all[df_all['train_val_or_test'] == 'train']\nprint(len(df_train))\nprint(len(df_val))\nprint(len(df_test))","metadata":{"id":"WnMfyVkEveb-","outputId":"4e00f8b3-2a5c-4612-a4f7-f09e360585f5","execution":{"iopub.status.busy":"2022-01-03T06:43:52.610826Z","iopub.execute_input":"2022-01-03T06:43:52.611163Z","iopub.status.idle":"2022-01-03T06:43:53.527822Z","shell.execute_reply.started":"2022-01-03T06:43:52.611119Z","shell.execute_reply":"2022-01-03T06:43:53.527090Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\ndf_train['dx'].value_counts().plot(x = df_train['dx'].value_counts(), kind='bar', color=[\"green\",\"yellow\", \"red\",  \"blue\", \"purple\",\"black\",\"cyan\"],title ='Training data distribution')\n# new helper method to auto-label bars","metadata":{"id":"VmnJW7kXveg2","outputId":"6d92bb4e-95e1-4ca3-df94-728fb02de92b","execution":{"iopub.status.busy":"2022-01-03T06:43:53.529206Z","iopub.execute_input":"2022-01-03T06:43:53.529453Z","iopub.status.idle":"2022-01-03T06:43:53.734634Z","shell.execute_reply.started":"2022-01-03T06:43:53.529420Z","shell.execute_reply":"2022-01-03T06:43:53.733977Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_val=df_val.reset_index(drop=True)\ndf_test=df_test.reset_index(drop=True)","metadata":{"id":"53uZftmoveiy","execution":{"iopub.status.busy":"2022-01-03T06:43:53.735895Z","iopub.execute_input":"2022-01-03T06:43:53.736166Z","iopub.status.idle":"2022-01-03T06:43:53.740798Z","shell.execute_reply.started":"2022-01-03T06:43:53.736118Z","shell.execute_reply":"2022-01-03T06:43:53.740043Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"weights = np.ceil(max(df_train['dx'].value_counts())/df_train['cell_type_idx'].value_counts())\nweights","metadata":{"id":"NNj6WjP5vCNb","outputId":"bcb79e58-09b3-4da6-be95-034b8fd02713","execution":{"iopub.status.busy":"2022-01-03T06:43:53.742992Z","iopub.execute_input":"2022-01-03T06:43:53.743571Z","iopub.status.idle":"2022-01-03T06:43:53.755270Z","shell.execute_reply.started":"2022-01-03T06:43:53.743533Z","shell.execute_reply":"2022-01-03T06:43:53.754429Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Duplicate some columns to make them balanced \n# Duplicate fewer class to balance through all classes\ndata_aug_rate = [6,4,2,15,1,2,12]\nfor i in range(7):\n    if data_aug_rate[i]:\n        df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\ndf_train['dx'].value_counts()","metadata":{"id":"8rDH0ccWvCPS","outputId":"add62448-ea24-4c43-ffcc-e18148fcb9a0","execution":{"iopub.status.busy":"2022-01-03T06:43:53.756850Z","iopub.execute_input":"2022-01-03T06:43:53.757143Z","iopub.status.idle":"2022-01-03T06:43:53.814469Z","shell.execute_reply.started":"2022-01-03T06:43:53.757103Z","shell.execute_reply":"2022-01-03T06:43:53.813786Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df_train['dx'].value_counts().plot(x = df_train['dx'].value_counts(), kind='bar', color=[\"green\",\"yellow\", \"red\",  \"blue\", \"purple\",\"black\",\"cyan\"],title ='Training data distribution')","metadata":{"execution":{"iopub.status.busy":"2022-01-03T06:43:53.815846Z","iopub.execute_input":"2022-01-03T06:43:53.816102Z","iopub.status.idle":"2022-01-03T06:43:54.030744Z","shell.execute_reply.started":"2022-01-03T06:43:53.816068Z","shell.execute_reply":"2022-01-03T06:43:54.030062Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#normMean = [0.7611847, 0.5426958, 0.56694466]\n#normStd = [0.13939652, 0.14886442, 0.1642639]\n#Define the transformation of the train images.\ninput_size = 128\ntrain_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n                                      transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n# define the transformation of the val images.\nval_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n                                    transforms.Normalize(norm_mean, norm_std)])\n# define the transformation of the test images.\ntest_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n                                    transforms.Normalize(norm_mean, norm_std)])","metadata":{"id":"Owbyc47rvCSr","execution":{"iopub.status.busy":"2022-01-03T06:43:54.032377Z","iopub.execute_input":"2022-01-03T06:43:54.032678Z","iopub.status.idle":"2022-01-03T06:43:54.039773Z","shell.execute_reply.started":"2022-01-03T06:43:54.032631Z","shell.execute_reply":"2022-01-03T06:43:54.039008Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Define a pytorch dataloader for this dataset\nclass HAM5000(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        # Load data and get label\n        X = Image.open(self.df['path'][index])\n        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n\n        if self.transform:\n            X = self.transform(X)\n\n        return X, y","metadata":{"id":"WDQYiQxav2FZ","execution":{"iopub.status.busy":"2022-01-03T06:43:54.041214Z","iopub.execute_input":"2022-01-03T06:43:54.041543Z","iopub.status.idle":"2022-01-03T06:43:54.053480Z","shell.execute_reply.started":"2022-01-03T06:43:54.041510Z","shell.execute_reply":"2022-01-03T06:43:54.052739Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Define the training set using the table train_df and using our defined transitions (train_transform)\ntraining_set = HAM5000(df_train, transform=train_transform)\ntrain_loader = DataLoader(training_set, batch_size=128, shuffle=True)\n#Doing the same for the validation set:\nvalidation_set = HAM5000(df_val, transform=val_transform)\nval_loader = DataLoader(validation_set, batch_size=128, shuffle=False)\n# And for the test set:\ntest_set = HAM5000(df_test, transform=test_transform)\ntest_loader = DataLoader(test_set, batch_size=len(df_test), shuffle=False)","metadata":{"id":"GwP7US6zv6hp","outputId":"88c9ae12-a8cd-43f1-eeab-ad5062a91594","execution":{"iopub.status.busy":"2022-01-03T06:43:54.054927Z","iopub.execute_input":"2022-01-03T06:43:54.055193Z","iopub.status.idle":"2022-01-03T06:43:54.063501Z","shell.execute_reply.started":"2022-01-03T06:43:54.055147Z","shell.execute_reply":"2022-01-03T06:43:54.062849Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementation of CNN/ConvNet Model\nclass CNN1(torch.nn.Module):\n\n    def __init__(self):\n        super(CNN1, self).__init__()\n\n        self.feature_extractor = nn.Sequential(\n            # L1 ImgIn shape=(?, 128, 128, 3)\n            # Conv -> (?, 126, 126, 16)\n            # Pool -> (?, 63, 63, 16)            \n            nn.Conv2d(3, 16, 3), #conv1\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n            #nn.Dropout(p=0.2),\n            \n            # L2 ImgIn shape=(?, 63, 63, 16)\n            # Conv      ->(?, 61, 61, 32)\n            # Pool      ->(?, 30, 30, 32)    \n            nn.Conv2d(16, 32, 3), #conv2\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2,stride =2),\n            nn.ReLU(),\n            #nn.Dropout(p=0.2),\n            ################################\n            # L3 ImgIn shape=(?, 30, 30, 32)\n            # Conv ->(?, 28, 28, 64)  \n            #   \n            nn.Conv2d(32, 64, 3), #conv3\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            #nn.Dropout(p=0.2),\n            #L4 ImgIn shape=(?, 28, 28, 64) \n            # Conv ->(?, 26, 26, 64)  \n            # Pool ->(?, 13, 13, 64)  \n            nn.Conv2d(64, 64, 3), #conv4\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(2,stride =2),\n            nn.ReLU(),\n            #nn.Dropout(p=0.2),\n            ####################################   \n\n        )    \n\n        # L7 FC 28x28x128 inputs -> 2048 outputs \n        self.fc1 = nn.Linear(13 * 13 * 64, 140)\n        torch.nn.init.xavier_uniform_(self.fc1.weight)   \n        self.layer4 = nn.Sequential(\n            self.fc1,\n            nn.ReLU(),\n            nn.Dropout(p=0.2))\n        \n        self.fc2 = nn.Linear(140, 32)\n        self.layer5 = nn.Sequential(self.fc2,nn.ReLU(),nn.Dropout(p=0.2))\n        # L8 Final FC 50 inputs -> 7 outputs\n        self.fc3 = nn.Linear(32, 7)\n        torch.nn.init.xavier_uniform_(self.fc3.weight) # initialize parameters        \n\n    def forward(self, x):\n        conv_features = self.feature_extractor(x)\n        #print(conv_features.shape)\n        conv_features = conv_features.view(x.shape[0], -1)\n        #out = out.view(out.size(0), -1)   \n        out = self.fc1(conv_features)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        return out\n\n\n#instantiate CNN model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel1= CNN1().to(device)\nsummary(model1,input_size=(3,128,128))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T06:43:54.064916Z","iopub.execute_input":"2022-01-03T06:43:54.065224Z","iopub.status.idle":"2022-01-03T06:44:04.818999Z","shell.execute_reply.started":"2022-01-03T06:43:54.065191Z","shell.execute_reply":"2022-01-03T06:44:04.818226Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-9_saNzR93ut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we use Adam optimizer, use cross entropy loss as our loss function\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau \noptimizer = optim.Adam(model1.parameters(), lr=5e-4, weight_decay=4e-3)\nscheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)","metadata":{"id":"Pc3g30aZv2bj","execution":{"iopub.status.busy":"2022-01-03T06:44:04.897140Z","iopub.execute_input":"2022-01-03T06:44:04.897406Z","iopub.status.idle":"2022-01-03T06:44:04.904390Z","shell.execute_reply.started":"2022-01-03T06:44:04.897371Z","shell.execute_reply":"2022-01-03T06:44:04.903703Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# this function is used during training process, to calculation the loss and accuracy\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"id":"ZyFnjjvSv2eV","execution":{"iopub.status.busy":"2022-01-03T06:44:04.908629Z","iopub.execute_input":"2022-01-03T06:44:04.910247Z","iopub.status.idle":"2022-01-03T06:44:04.916401Z","shell.execute_reply.started":"2022-01-03T06:44:04.910219Z","shell.execute_reply":"2022-01-03T06:44:04.915674Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"total_loss_train, total_acc_train = [],[]\ndef train(train_loader,device, model, criterion, optimizer, epoch, scheduler):\n    model.train()\n    train_loss = AverageMeter()\n    train_acc = AverageMeter()\n    curr_iter = (epoch - 1) * len(train_loader)\n    # initialize the early_stopping object\n    #early_stopping = EarlyStopping(patience=patience, verbose=True)\n    for i, data in enumerate(train_loader):\n        images, labels = data\n        N = images.size(0)\n        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n        images = Variable(images).to(device)\n        labels = Variable(labels).to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        prediction = outputs.max(1, keepdim=True)[1]\n        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n        train_loss.update(loss.item())\n        curr_iter += 1\n        if (i + 1) % 25 == 0:\n            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n            total_loss_train.append(train_loss.avg)\n            total_acc_train.append(train_acc.avg)\n    return train_loss.avg, train_acc.avg","metadata":{"id":"cVlMJQBTv2gv","execution":{"iopub.status.busy":"2022-01-03T06:44:04.918292Z","iopub.execute_input":"2022-01-03T06:44:04.918541Z","iopub.status.idle":"2022-01-03T06:44:04.929774Z","shell.execute_reply.started":"2022-01-03T06:44:04.918508Z","shell.execute_reply":"2022-01-03T06:44:04.928179Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def validate(val_loader,device,  model, criterion, optimizer, epoch,scheduler):\n    model.eval()\n    val_loss = AverageMeter()\n    val_acc = AverageMeter()\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            images, labels = data\n            N = images.size(0)\n            images = Variable(images).to(device)\n            labels = Variable(labels).to(device)\n\n            outputs = model(images)\n            prediction = outputs.max(1, keepdim=True)[1]\n\n            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n\n            val_loss.update(criterion(outputs, labels).item())\n\n    print('------------------------------------------------------------')\n    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n    print('------------------------------------------------------------')\n    return val_loss.avg, val_acc.avg","metadata":{"id":"EzpcxurmyDiI","execution":{"iopub.status.busy":"2022-01-03T06:44:04.931095Z","iopub.execute_input":"2022-01-03T06:44:04.931491Z","iopub.status.idle":"2022-01-03T06:44:04.941262Z","shell.execute_reply.started":"2022-01-03T06:44:04.931455Z","shell.execute_reply":"2022-01-03T06:44:04.940451Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss().to(device)\nprint('Running on: ',device)\n\nepoch_num = 50\nbest_val_acc = 0\ntotal_loss_val, total_acc_val = [],[]\ntotal_loss_tr, total_acc_tr = [],[]\nfor epoch in range(1, epoch_num+1):\n    loss_train, acc_train = train(train_loader, device, model1, criterion, optimizer, epoch, scheduler)\n    loss_val, acc_val = validate(val_loader, device, model1, criterion, optimizer, epoch, scheduler)\n    total_loss_val.append(loss_val)\n    total_acc_val.append(acc_val)\n    total_loss_tr.append(loss_train)\n    total_acc_tr.append(acc_train)    \n    if acc_val > best_val_acc:\n        best_val_acc = acc_val\n        print('*****************************************************')\n        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n        print('*****************************************************')\n    scheduler.step(loss_val)\n","metadata":{"id":"jjxnhn1q1gv_","outputId":"af79be29-6d07-4818-89f0-ea38e4e9a113","execution":{"iopub.status.busy":"2022-01-03T06:44:04.943991Z","iopub.execute_input":"2022-01-03T06:44:04.944834Z","iopub.status.idle":"2022-01-03T08:33:02.123474Z","shell.execute_reply.started":"2022-01-03T06:44:04.944797Z","shell.execute_reply":"2022-01-03T08:33:02.121872Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig1 = fig.add_subplot(2,1,1)\nfig2 = fig.add_subplot(2,1,2)\n#fig1 = fig.add_subplot(2,1,1)\nfig1.plot(total_loss_tr, label = 'Training loss')\nfig1.plot(total_loss_val, label = 'Validation loss',linestyle='--')\nfig2.plot(total_acc_tr, label = 'Training Accuracy')\nfig2.plot(total_acc_val, label ='validation accuracy',linestyle='--')\nplt.legend()\nplt.show()","metadata":{"id":"iNb3umERpeU5","outputId":"30647f7c-f6f7-49e0-c055-3a95b2b19e0c","execution":{"iopub.status.busy":"2022-01-03T08:33:02.126102Z","iopub.execute_input":"2022-01-03T08:33:02.126377Z","iopub.status.idle":"2022-01-03T08:33:02.402695Z","shell.execute_reply.started":"2022-01-03T08:33:02.126336Z","shell.execute_reply":"2022-01-03T08:33:02.401993Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"XjD4_1qHpi3I","outputId":"e3cde95a-f843-4857-cd03-9edbb18b78f7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\n\nfig1 = fig.add_subplot(1,1,1)\n#fig1 = fig.add_subplot(2,1,1)\nfig1.plot(total_loss_tr, label = 'Training loss')\nfig1.plot(total_loss_val, label = 'Validation loss',linestyle='--')\nplt.legend()\nplt.show()","metadata":{"id":"0bjlF0nMpUhW","outputId":"41c2f9f2-a264-4909-c44e-10e96adaec37","execution":{"iopub.status.busy":"2022-01-03T08:33:02.404091Z","iopub.execute_input":"2022-01-03T08:33:02.404578Z","iopub.status.idle":"2022-01-03T08:33:02.765702Z","shell.execute_reply.started":"2022-01-03T08:33:02.404540Z","shell.execute_reply":"2022-01-03T08:33:02.765013Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig2 = fig.add_subplot(1,1,1)\nfig2.plot(total_acc_tr, label = 'Training Accuracy')\nfig2.plot(total_acc_val, label ='validation accuracy',linestyle='--')\nplt.legend()\nplt.show()","metadata":{"id":"Kye9Wo3DpaPq","outputId":"6c148c72-a67c-4889-9062-12b770af2e11","execution":{"iopub.status.busy":"2022-01-03T08:33:02.767079Z","iopub.execute_input":"2022-01-03T08:33:02.767355Z","iopub.status.idle":"2022-01-03T08:33:02.949743Z","shell.execute_reply.started":"2022-01-03T08:33:02.767320Z","shell.execute_reply":"2022-01-03T08:33:02.949019Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                      normalize=False,\n                      title='Confusion matrix',\n                      cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"id":"-6cxwihkyDj3","execution":{"iopub.status.busy":"2022-01-03T08:33:02.951088Z","iopub.execute_input":"2022-01-03T08:33:02.951360Z","iopub.status.idle":"2022-01-03T08:33:02.959389Z","shell.execute_reply.started":"2022-01-03T08:33:02.951326Z","shell.execute_reply":"2022-01-03T08:33:02.958607Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def test(test_loader,device,  model, criterion):\n    model.eval()\n    test_loss = AverageMeter()\n    test_acc = AverageMeter()\n    with torch.no_grad():\n        for i, data in enumerate(test_loader):\n            images, labels = data\n            N = images.size(0)\n            images = Variable(images).to(device)\n            labels = Variable(labels).to(device)\n\n            outputs = model(images)\n            prediction = outputs.max(1, keepdim=True)[1]\n\n            test_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n\n            test_loss.update(criterion(outputs, labels).item())\n\n    print('------------------------------------------------------------')\n    print('[epoch %d], [test loss %.5f], [test acc %.5f]' % (1, test_loss.avg, test_acc.avg))\n    print('------------------------------------------------------------')\n    return test_loss.avg, test_acc.avg","metadata":{"id":"3Z1CTU3v4Gf4","execution":{"iopub.status.busy":"2022-01-03T08:33:02.960947Z","iopub.execute_input":"2022-01-03T08:33:02.961216Z","iopub.status.idle":"2022-01-03T08:33:02.970631Z","shell.execute_reply.started":"2022-01-03T08:33:02.961181Z","shell.execute_reply":"2022-01-03T08:33:02.969949Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"loss_test, acc_test = test(test_loader, device, model1, criterion)","metadata":{"id":"hhih8F4D3m7V","outputId":"acb7ae42-a3f8-476c-ac48-4fc17fcd76a9","execution":{"iopub.status.busy":"2022-01-03T08:33:02.972031Z","iopub.execute_input":"2022-01-03T08:33:02.972592Z","iopub.status.idle":"2022-01-03T08:33:10.892194Z","shell.execute_reply.started":"2022-01-03T08:33:02.972553Z","shell.execute_reply":"2022-01-03T08:33:10.890552Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# sklearn libraries\nimport itertools\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"id":"tjKlUN5JyDkq","execution":{"iopub.status.busy":"2022-01-03T08:33:10.893782Z","iopub.execute_input":"2022-01-03T08:33:10.894061Z","iopub.status.idle":"2022-01-03T08:33:10.898851Z","shell.execute_reply.started":"2022-01-03T08:33:10.894023Z","shell.execute_reply":"2022-01-03T08:33:10.897764Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"small_test = test_loader.dataset.df[:][0:300]\nsmall_test_set = HAM5000(small_test, transform=test_transform)\nsmall_test_loader = DataLoader(small_test_set, batch_size=len(small_test), shuffle=False)","metadata":{"id":"X8gcXGZ60xr3","execution":{"iopub.status.busy":"2021-12-22T18:01:04.421819Z","iopub.execute_input":"2021-12-22T18:01:04.42245Z","iopub.status.idle":"2021-12-22T18:01:04.430674Z","shell.execute_reply.started":"2021-12-22T18:01:04.422376Z","shell.execute_reply":"2021-12-22T18:01:04.429971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.eval()\ny_label = []\ny_predict = []\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        images, labels = data\n        N = images.size(0)\n        images = Variable(images).to(device)\n        outputs = model1(images)\n        prediction = outputs.max(1, keepdim=True)[1]\n        y_label.extend(labels.cpu().numpy())\n        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_label, y_predict)\n# plot the confusion matrix\nplot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\nplot_confusion_matrix(confusion_mtx, plot_labels)","metadata":{"id":"o50u_6akr4qW","outputId":"5f3abf54-d44c-4445-ff58-4604c50cf891","execution":{"iopub.status.busy":"2022-01-03T08:33:10.900530Z","iopub.execute_input":"2022-01-03T08:33:10.901141Z","iopub.status.idle":"2022-01-03T08:33:19.189996Z","shell.execute_reply.started":"2022-01-03T08:33:10.901101Z","shell.execute_reply":"2022-01-03T08:33:19.189229Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report\nreport = classification_report(y_label, y_predict, target_names=plot_labels)\nprint(report)","metadata":{"id":"K9Rs9eghv2ic","outputId":"2a048e45-e256-468d-b4b4-c21ac15409fa","execution":{"iopub.status.busy":"2022-01-03T08:33:19.192614Z","iopub.execute_input":"2022-01-03T08:33:19.193294Z","iopub.status.idle":"2022-01-03T08:33:19.204630Z","shell.execute_reply.started":"2022-01-03T08:33:19.193250Z","shell.execute_reply":"2022-01-03T08:33:19.203798Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Save\ntorch.save(model1.state_dict(),'Trained_CNN_Model1.pt')","metadata":{"id":"ip7a2hjMFJCQ","execution":{"iopub.status.busy":"2022-01-03T08:33:19.206114Z","iopub.execute_input":"2022-01-03T08:33:19.206450Z","iopub.status.idle":"2022-01-03T08:33:19.228628Z","shell.execute_reply.started":"2022-01-03T08:33:19.206413Z","shell.execute_reply":"2022-01-03T08:33:19.227902Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:58:05.669502Z","iopub.execute_input":"2021-12-22T13:58:05.66976Z","iopub.status.idle":"2021-12-22T13:58:05.691852Z","shell.execute_reply.started":"2021-12-22T13:58:05.669724Z","shell.execute_reply":"2021-12-22T13:58:05.691224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_state_dict(torch.load('Trained_CNN_Model1.pt'))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:11:41.934182Z","iopub.execute_input":"2022-01-01T12:11:41.934442Z","iopub.status.idle":"2022-01-01T12:11:41.951599Z","shell.execute_reply.started":"2022-01-01T12:11:41.934413Z","shell.execute_reply":"2022-01-01T12:11:41.950879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing on a random image in the dataset\ntest_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n                                    transforms.Normalize(norm_mean, norm_std)])\nrandom_test_set = HAM5000(df_test[0:5], transform=test_transform)\nrandom_test_loader = DataLoader(random_test_set, batch_size=len(random_test_set), shuffle=False) \nwith torch.no_grad():\n    for i, data in enumerate(random_test_loader):\n        images, labels = data\n        N = images.size(0)\n        images = Variable(images).to(device)\n        outputs = model1(images)\n        prediction = outputs.max(1, keepdim=True)[1]\n        y_label.extend(labels.cpu().numpy())\n        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n        \nprint('Prediction:',y_predict[:5],'\\nTrue label:',y_label[:5])     ","metadata":{"id":"Kli0O3Skv2lG","execution":{"iopub.status.busy":"2022-01-03T08:33:19.229692Z","iopub.execute_input":"2022-01-03T08:33:19.232312Z","iopub.status.idle":"2022-01-03T08:33:19.305083Z","shell.execute_reply.started":"2022-01-03T08:33:19.232269Z","shell.execute_reply":"2022-01-03T08:33:19.304186Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:54:43.477644Z","iopub.execute_input":"2021-12-22T13:54:43.478202Z","iopub.status.idle":"2021-12-22T13:54:43.498412Z","shell.execute_reply.started":"2021-12-22T13:54:43.478162Z","shell.execute_reply":"2021-12-22T13:54:43.497768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nfrom torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\ntorch.manual_seed(42)\n\ncriterion = nn.CrossEntropyLoss().to(device)\n\ndataset = ConcatDataset([training_set, validation_set, test_set])\n\nnum_epochs=30\nbatch_size=128\nk=4\nsplits=KFold(n_splits=k,shuffle=True,random_state=42)\nfoldperf={}","metadata":{"id":"UiOdv936v9Js","execution":{"iopub.status.busy":"2022-01-03T08:33:19.306648Z","iopub.execute_input":"2022-01-03T08:33:19.306940Z","iopub.status.idle":"2022-01-03T08:33:19.313445Z","shell.execute_reply.started":"2022-01-03T08:33:19.306903Z","shell.execute_reply":"2022-01-03T08:33:19.312623Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model,device,dataloader,loss_fn,optimizer):\n    train_loss,train_correct=0.0,0\n    model.train()\n    for images, labels in dataloader:\n\n        images,labels = images.to(device),labels.to(device)\n        optimizer.zero_grad()\n        output = model(images)\n        loss = loss_fn(output,labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * images.size(0)\n        scores, predictions = torch.max(output.data, 1)\n        train_correct += (predictions == labels).sum().item()\n\n    return train_loss,train_correct\n  \ndef valid_epoch(model,device,dataloader,loss_fn):\n    valid_loss, val_correct = 0.0, 0\n    model.eval()\n    for images, labels in dataloader:\n        images,labels = images.to(device),labels.to(device)\n        output = model(images)\n        loss=loss_fn(output,labels)\n        valid_loss+=loss.item()*images.size(0)\n        scores, predictions = torch.max(output.data,1)\n        val_correct+=(predictions == labels).sum().item()\n\n    return valid_loss,val_correct","metadata":{"id":"K4uVx2Kpw6jc","execution":{"iopub.status.busy":"2022-01-03T08:33:19.314747Z","iopub.execute_input":"2022-01-03T08:33:19.316914Z","iopub.status.idle":"2022-01-03T08:33:19.327740Z","shell.execute_reply.started":"2022-01-03T08:33:19.316873Z","shell.execute_reply":"2022-01-03T08:33:19.326886Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"LOSS = []\nACCURACY = []\n\nVAL_LOSS = []\nVAL_ACCURACY  = []\nfor fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n\n    print('Fold {}'.format(fold + 1))\n\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(val_idx)\n    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    model = CNN1()\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.002)\n\n    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n\n    for epoch in range(num_epochs):\n        train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n        test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n\n        train_loss = train_loss / len(train_loader.sampler)\n        train_acc = train_correct / len(train_loader.sampler) * 100\n        test_loss = test_loss / len(test_loader.sampler)\n        test_acc = test_correct / len(test_loader.sampler) * 100\n\n        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n                                                                                                             num_epochs,\n                                                                                                             train_loss,\n                                                                                                             test_loss,\n                                                                                                             train_acc,\n                                                                                                             test_acc))\n        history['train_loss'].append(train_loss)\n        history['test_loss'].append(test_loss)\n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)\n        LOSS.append(train_loss)\n        ACCURACY.append(train_acc)\n        VAL_LOSS.append(test_loss)\n        VAL_ACCURACY.append(test_acc)\n\n    foldperf['fold{}'.format(fold+1)] = history  \n\ntorch.save(model,'k_cross_CNN.pt') ","metadata":{"id":"VNtxsLp2v9Me","outputId":"2ffdab95-2f38-4ed2-e483-8cf0bc70da21","execution":{"iopub.status.busy":"2022-01-03T08:33:19.329245Z","iopub.execute_input":"2022-01-03T08:33:19.329929Z","iopub.status.idle":"2022-01-03T13:07:37.754801Z","shell.execute_reply.started":"2022-01-03T08:33:19.329888Z","shell.execute_reply":"2022-01-03T13:07:37.754041Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"x_axis = np.arange(1,num_epochs+1)\nfig, ax = plt.subplots(4,2,constrained_layout=True, figsize=(13,16))\n\nfor i in range(4): \n    ax[i,0].set_title('Fold' + str(i+1) + ' Loss')\n    ax[i,0].set_xlabel('Epoch')    \n    ax[i,0].set_ylabel('Loss')\n    ax[i,0].plot(x_axis, LOSS[num_epochs*i:num_epochs*(i+1)],label='Training loss')\n    ax[i,0].plot(x_axis, VAL_LOSS[num_epochs*i:num_epochs*(i+1)],label='Validation loss', linestyle='--')\n    ax[i,0].legend()\n    \n    ax[i,1].set_title('Fold' + str(i+1) + ' Accuracy')\n    ax[i,1].set_ylabel('Accuracy')\n    ax[i,1].plot(x_axis, ACCURACY[num_epochs*i:num_epochs*(i+1)]/(np.ones((num_epochs,))*100.0),label='Training accuracy')\n    ax[i,1].plot(x_axis, VAL_ACCURACY[num_epochs*i:num_epochs*(i+1)]/(np.ones((num_epochs,))*100.0),label='Validation accuracy', linestyle='--')\n    ax[i,1].set_xlabel('Epoch')\n    ax[i,1].set_ylim((0,1))\n    ax[i,1].set_xticks(np.arange(0,num_epochs+1,5))\n    ax[i,1].legend()","metadata":{"id":"pDJuKnxIv9PY","execution":{"iopub.status.busy":"2022-01-03T13:21:04.398716Z","iopub.execute_input":"2022-01-03T13:21:04.398974Z","iopub.status.idle":"2022-01-03T13:21:05.917595Z","shell.execute_reply.started":"2022-01-03T13:21:04.398944Z","shell.execute_reply":"2022-01-03T13:21:05.916814Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"loss = [LOSS[x:x+num_epochs] for x in range(0, len(LOSS), num_epochs)]\nval_loss = [VAL_LOSS[x:x+num_epochs] for x in range(0, len(VAL_LOSS), num_epochs)]\nacc = [ACCURACY[x:x+num_epochs] for x in range(0, len(ACCURACY), num_epochs)]\nval_acc = [VAL_ACCURACY[x:x+num_epochs] for x in range(0, len(VAL_ACCURACY), num_epochs)]\n","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:27:15.815202Z","iopub.execute_input":"2022-01-03T13:27:15.815871Z","iopub.status.idle":"2022-01-03T13:27:15.821709Z","shell.execute_reply.started":"2022-01-03T13:27:15.815835Z","shell.execute_reply":"2022-01-03T13:27:15.821054Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"loss = [sum(sub_list) / len(sub_list) for sub_list in zip(*loss)]\nval_loss = [sum(sub_list) / len(sub_list) for sub_list in zip(*val_loss)]\nacc = [sum(sub_list) / len(sub_list) for sub_list in zip(*acc)]\nval_acc = [sum(sub_list) / len(sub_list) for sub_list in zip(*val_acc)]","metadata":{"id":"WlND1qoev9R8","execution":{"iopub.status.busy":"2022-01-03T13:27:17.595027Z","iopub.execute_input":"2022-01-03T13:27:17.595551Z","iopub.status.idle":"2022-01-03T13:27:17.600882Z","shell.execute_reply.started":"2022-01-03T13:27:17.595513Z","shell.execute_reply":"2022-01-03T13:27:17.600110Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_axis = np.arange(1,num_epochs+1)\nfig, ax = plt.subplots(1,2,constrained_layout=True, figsize=(12,5))\n\nax[0].set_title('Average Loss after 4 folds training')\nax[0].set_ylabel('Loss')\nax[0].set_xlabel('Epoch')\nax[0].plot(x_axis, loss,label='Training loss')\nax[0].plot(x_axis, val_loss,label='Validation loss', linestyle='--')\nax[0].legend()\n\nax[1].set_title('Average Accuracy after 4 folds training')\nax[1].set_ylabel('Accuracy')\nax[1].plot(x_axis, acc/(np.ones((num_epochs,))*100.0),label='Training accuracy')\nax[1].plot(x_axis, val_acc/(np.ones((num_epochs,))*100.0),label='Validation accuracy', linestyle='--')\nax[1].set_xlabel('Epoch')\nax[1].set_ylim((0,1))\nax[1].set_xticks(np.arange(0,num_epochs+1,5))\nax[1].legend()","metadata":{"id":"VmCtt143v9Un","execution":{"iopub.status.busy":"2022-01-03T13:28:36.133503Z","iopub.execute_input":"2022-01-03T13:28:36.133771Z","iopub.status.idle":"2022-01-03T13:28:36.630614Z","shell.execute_reply.started":"2022-01-03T13:28:36.133741Z","shell.execute_reply":"2022-01-03T13:28:36.629954Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"torch.load(model,'k_cross_CNN.pt') ","metadata":{"execution":{"iopub.status.busy":"2022-01-02T12:38:31.283193Z","iopub.execute_input":"2022-01-02T12:38:31.28416Z","iopub.status.idle":"2022-01-02T12:38:31.316541Z","shell.execute_reply.started":"2022-01-02T12:38:31.284124Z","shell.execute_reply":"2022-01-02T12:38:31.315123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ny_label = []\ny_predict = []\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        images, labels = data\n        N = images.size(0)\n        images = Variable(images).to(device)\n        outputs = model(images)\n        prediction = outputs.max(1, keepdim=True)[1]\n        y_label.extend(labels.cpu().numpy())\n        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_label, y_predict)\n# plot the confusion matrix\nplot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\nplot_confusion_matrix(confusion_mtx, plot_labels)","metadata":{"id":"cglKqJSzv9XJ","execution":{"iopub.status.busy":"2022-01-03T13:08:16.290995Z","iopub.execute_input":"2022-01-03T13:08:16.291327Z","iopub.status.idle":"2022-01-03T13:08:50.603392Z","shell.execute_reply.started":"2022-01-03T13:08:16.291289Z","shell.execute_reply":"2022-01-03T13:08:50.602688Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report\nreport = classification_report(y_label, y_predict, target_names=plot_labels)\nprint(report)","metadata":{"id":"2auNvaafv9Za","execution":{"iopub.status.busy":"2022-01-03T13:08:50.604688Z","iopub.execute_input":"2022-01-03T13:08:50.605103Z","iopub.status.idle":"2022-01-03T13:08:50.622487Z","shell.execute_reply.started":"2022-01-03T13:08:50.605066Z","shell.execute_reply":"2022-01-03T13:08:50.621814Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZcyqrkX7v9cJ"},"execution_count":null,"outputs":[]}]}